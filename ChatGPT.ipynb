{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "391eef98",
   "metadata": {},
   "source": [
    "```\n",
    "C:\\ProgramData\\anaconda3>python -m pip install openai  \n",
    "C:\\ProgramData\\anaconda3>python -m pip install python-dotenv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba382396",
   "metadata": {},
   "source": [
    "## Load the API key and relevant Python libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d1252ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "584927d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aafe82f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nSummarize the text delimited by triple backticks \\\\ \\ninto a single sentence.\\n```\\nYou should express what you want a model to do by \\\\ \\nproviding instructions that are as clear and \\\\ \\nspecific as you can possibly make them. \\\\ \\nThis will guide the model towards the desired output, \\\\ \\nand reduce the chances of receiving irrelevant \\\\ \\nor incorrect responses. Don't confuse writing a \\\\ \\nclear prompt with writing a short prompt. \\\\ \\nIn many cases, longer prompts provide more clarity \\\\ \\nand context for the model, which can lead to \\\\ \\nmore detailed and relevant outputs.\\n```\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "You should express what you want a model to do by \\ \n",
    "providing instructions that are as clear and \\ \n",
    "specific as you can possibly make them. \\ \n",
    "This will guide the model towards the desired output, \\ \n",
    "and reduce the chances of receiving irrelevant \\ \n",
    "or incorrect responses. Don't confuse writing a \\ \n",
    "clear prompt with writing a short prompt. \\ \n",
    "In many cases, longer prompts provide more clarity \\ \n",
    "and context for the model, which can lead to \\ \n",
    "more detailed and relevant outputs.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks \\ \n",
    "into a single sentence.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df27d822",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# response = get_completion(prompt)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71933cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
